{
  "hash": "4b31f1046a57eefbdccb0c7d22118198",
  "result": {
    "engine": "knitr",
    "markdown": "# Simulation example {#sec-ex2}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Load packages\nlibrary(ggdag)\nlibrary(dagitty)\nlibrary(rstanarm)\nlibrary(tidybayes)\nlibrary(ggdist)\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(rstan)\n```\n:::\n\n\n\n\n## Data-generating process\n\nThe data-generating process is described via the directed acyclic graph (DAG) in @fig-DAG.ex2-1. In this DAG, glare perception $(\\text{G})$ is directly influenced by social interaction $(\\text{I})$ and window state $(\\text{W})$, and indirectly by occupancy $(\\text{O})$ through social interaction $(\\text{I})$. Additionally, occupancy $(\\text{O})$ and window state $(\\text{W})$ directly influence CO~2~ concentration $(\\text{C})$.\n\n\n\n\n::: {.cell .fig-cap-location-bottom layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\ndag_coords.ex2 <-\n  data.frame(name = c('I', 'O', 'C', 'G', 'W'),\n             x = c(1, 1, 3.5, 6, 6),\n             y = c(1, 3, 2, 1, 3))\n\nDAG.ex2 <-\n  dagify(I ~ O,\n         C ~ O,\n         C ~ W,\n         G ~ W,\n         G ~ I + W,\n         coords = dag_coords.ex2)\n\nggplot(data = DAG.ex2, aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_text(colour = 'black', size = 10, parse = TRUE,\n                family = c('mono'),\n                label = c(expression(bold(C)), expression(bold(G)), expression(bold(I)), expression(bold(O)), expression(bold(W)))) +\n  geom_dag_edges(arrow_directed = grid::arrow(length = grid::unit(10, 'pt'), type = 'open'),\n                 edge_colour = 'black',\n                 family = c('mono'), \n                 fontface = c('bold')) + \n  annotate('text', x = 1, y = 0.7, label = 'social interaction', \n           size = 4, hjust = 0.5, colour = 'grey50') +\n  annotate('text', x = 3.5, y = 1.7, label = 'CO2', \n           size = 4, hjust = 0.5, colour = 'grey50') +\n  annotate('text', x = 1, y = 3.3, label = 'occupancy', \n           size = 4, hjust = 0.5, colour = 'grey50') +\n    annotate('text', x = 6, y = 3.3, label = 'window state', \n           size = 4, hjust = 0.5, colour = 'grey50') +\n    annotate('text', x = 6, y = 0.7, label = 'glare perception', \n           size = 4, hjust = 0.5, colour = 'grey50') +\n  coord_cartesian(xlim = c(0.5, 6.5), ylim = c(0.8, 3.2))  +\n  theme_dag()\n```\n\n::: {.cell-output-display}\n![Graphical representation via DAG of the data-generating process.](ex2_simulation_files/figure-html/fig-DAG.ex2-1-1.png){#fig-DAG.ex2-1 fig-align='center' width=60%}\n:::\n:::\n\n\n\n\nThe DAG in @fig-DAG.ex2-1 can be written as:\n\n-   $I \\sim f_{I}(O)$, read as 'social interaction $(\\text{I})$ is some function of occupancy $(\\text{O})$'.\n-   $C \\sim f_{C}(O, W)$, read as 'CO~2~ concentration $(\\text{C})$ is some function of occupancy $(\\text{O})$ and window $(\\text{W})$'.\n-   $G \\sim f_{G}(I, W)$, read as 'glare perception $(\\text{G})$ is some function of social interaction $(\\text{I})$ and window $(\\text{W})$'.\n\n## Synthetic data set\n\nTo generate synthetic data, we defined the custom function `data.sim_ex2()`. This function takes as inputs the sample size `n` and generates synthetic data according to the DAG in @fig-DAG.ex2-1.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.sim_ex2 <- function(n) {\n  b_socint.glare = -2 #direct causal effect of I on G\n  b_win.glare = c(0, 20) #direct causal effect of W on G\n  #Simulate occupancy\n  O <- factor(sample(c('low', 'high'), size = n, replace = TRUE))  \n  #Simulate window state\n  W <- factor(sample(c('closed', 'open'), size = n, replace = TRUE))  \n  #Simulate CO2\n  C <- rnorm(n = n, mean = 400 + ifelse(O == 'low', 0, 50) + ifelse(W == 'closed', 0, 30), sd = 10)\n  #Simulate social interaction\n  I <- rpois(n = n, lambda = 7 + ifelse(O == 'low', 0, 3))  \n  #Simulate glare perception \n  G <- rnorm(n = n, mean = 50 + b_socint.glare * I + ifelse(W == 'closed', b_win.glare[1], b_win.glare[2]), sd = 5)\n  #Return tibble with simulated values\n  return(tibble(O, I, C, W, G))\n  }\n```\n:::\n\n\n\n\nFrom this data generation mechanism, we simulated the target population, which consists of one million observations.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2025) #set random number for reproducibility\n#Simulate the population\nex2_population <- data.sim_ex2(n = 1e6)\n#Set occupancy reference category to 'low'\nex2_population$O <- relevel(ex2_population$O, ref = 'low')\n#Set window state reference category to 'closed'\nex2_population$W <- relevel(ex2_population$W, ref = 'closed')\n#View the data frame\nex2_population\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,000,000 × 5\n   O         I     C W          G\n   <fct> <int> <dbl> <fct>  <dbl>\n 1 low       5  422. closed  41.3\n 2 high      6  474. closed  42.5\n 3 high     13  473. open    35.9\n 4 high     11  461. open    42.1\n 5 low       2  391. closed  43.8\n 6 low      12  404. closed  18.4\n 7 high     16  452. closed  24.0\n 8 low      10  416. open    54.2\n 9 high     15  496. open    33.4\n10 low       5  415. open    50.4\n# ℹ 999,990 more rows\n```\n\n\n:::\n:::\n\n\n\n\nFrom this population, we obtained one data set of a five thousand observations using simple random sampling.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_sims <- 1e3 #number of data sets to simulate\n\n#Set random number for reproducibility\nset.seed(2025)  \n#Generate a vector of random numbers for reproducibility\nex2_random.seed <- sample(1:1e5, size = n_sims, replace = FALSE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(ex2_random.seed[1])\n#Sample one data set of 5,000 observations\nex2_sample.random <- \n  ex2_population %>% \n  slice_sample(n = 5e3) #take a simple random sample of size 5,000 \n\n#View the data frame\nex2_sample.random\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5,000 × 5\n   O         I     C W          G\n   <fct> <int> <dbl> <fct>  <dbl>\n 1 high     11  463. closed  32.9\n 2 low      11  404. closed  27.3\n 3 low       2  393. closed  40.5\n 4 high     10  481. open    45.5\n 5 low       7  398. closed  38.2\n 6 low       6  422. open    62.4\n 7 high     11  472. open    47.9\n 8 low       5  424. open    58.3\n 9 high     13  465. open    47.2\n10 low       6  417. open    64.5\n# ℹ 4,990 more rows\n```\n\n\n:::\n:::\n\n\n\n\n## Data analysis\n\nIn this example, the target of our analysis is the total average causal effect, ACE (also known as total average treatment effect, ATE) of social interaction $(\\text{I})$ on glare perception $(\\text{G})$, which stands for the expected increase of $\\text{G}$ in response to a unit increase in $\\text{I}$ due to an intervention. The causal effect of interest is visualized in @fig-DAG.ex2-2.\n\n\n\n\n::: {.cell .fig-cap-location-bottom layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(data = DAG.ex2, aes(x = x, y = y, xend = xend, yend = yend)) +\n  #visualise causal effect path\n  geom_segment(x = 1, xend = 6, y = 1, yend = 1,\n               linewidth = 14, lineend = 'round', colour = '#009E73', alpha = 0.05) +\n  geom_dag_text(colour = 'black', size = 10, parse = TRUE,\n                family = c('mono'),\n                label = c(expression(bold(C)), expression(bold(G)), expression(bold(I)), expression(bold(O)), expression(bold(W)))) +\n  geom_dag_edges(arrow_directed = grid::arrow(length = grid::unit(10, 'pt'), type = 'open'),\n                 edge_colour = 'black',\n                 family = c('mono'), \n                 fontface = c('bold')) + \n  annotate('text', x = 1, y = 0.7, label = 'social interaction', \n           size = 4, hjust = 0.5, colour = 'grey50') +\n  annotate('text', x = 3.5, y = 1.7, label = 'CO2', \n           size = 4, hjust = 0.5, colour = 'grey50') +\n  annotate('text', x = 1, y = 3.3, label = 'occupancy', \n           size = 4, hjust = 0.5, colour = 'grey50') +\n  annotate('text', x = 6, y = 3.3, label = 'window state', \n           size = 4, hjust = 0.5, colour = 'grey50') +\n  annotate('text', x = 6, y = 0.7, label = 'glare perception', \n           size = 4, hjust = 0.5, colour = 'grey50') +\n  #causal effect number\n  annotate('text', x = 3.5, y = 1.2, label = '-2', \n           size = 4.5, hjust = 0.5, colour = 'black', parse = TRUE) +\n  coord_cartesian(xlim = c(0.5, 6.5), ylim = c(0.8, 3.2))  +\n  theme_dag()\n```\n\n::: {.cell-output-display}\n![Graphical representation via DAG of the data-generating process. The green line indicates the causal question of interest, and the number on the path indicates the total average causal effect.](ex2_simulation_files/figure-html/fig-DAG.ex2-2-1.png){#fig-DAG.ex2-2 fig-align='center' width=60%}\n:::\n:::\n\n\n\n\n### Identification\n\nThe first step to answer the causal question of interest is identification. Identification answers a ‘theoretical’ question by determining whether a causal effect can, in principle, be estimated from observed data. The backdoor criterion and its generalization, the adjustment criterion, allow us to understand whether our causal effect of interest can be identified and, if so, which variables we should (or should not) statistically adjust for (i.e., the adjustment set) to estimate the causal effect from the data.\n\nGiven its simplicity, we will first apply the backdoor criterion to identify valid adjustment sets to estimate the causal effect of interest. If the backdoor criterion is not applicable, we will apply its generalization, the adjustment criterion.\n\n#### Backdoor criterion\n\nApplying the backdoor criterion revealed the absence of any backdoor path (i.e., a non-causal path) from social interaction $(\\text{I})$ to glare perception $(\\text{G})$. As a result, there is no confounding and no adjustement is required.\n\nGiven the DAG in @fig-DAG.ex2-2, we can use the `adjustmentSets()` function to identify the adjustment set algorithmically. It is essential to note that this function applies the adjustment criterion and not the backdoor criterion. As such, the `adjustmentSets()` function can find adjustment sets even when the backdoor criterion is not applicable.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nadjustmentSets(DAG.ex2,\n               exposure = 'I', #social interaction\n               outcome = 'G', #glare perception\n               type = 'all', \n               effect = 'total', \n               max.results = Inf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n {}\n{ O }\n{ C, O }\n{ W }\n{ C, W }\n{ O, W }\n{ C, O, W }\n```\n\n\n:::\n:::\n\n\n\n\nAs expected, the resulting adjustment set includes the empty set (i.e., no adjustment is required). However, the backdoor criterion reveals that there are six other possible adjustment sets to get the correct estimate of the total average causal effect of $\\text{I}$ on $\\text{G}$. Specifically:\n\n-   adjust for occupancy $(\\text{O})$\n-   adjust for CO~2~ concentration $(\\text{C})$ and occupancy $(\\text{O})$\n-   adjust for window state $(\\text{W})$\n-   adjust for CO~2~ concentration $(\\text{C})$ and window state $(\\text{W})$\n-   adjust for occupancy $(\\text{O})$ and window state $(\\text{W})$\n-   adjust for CO~2~ concentration $(\\text{C})$, occupancy $(\\text{O})$ and window state $(\\text{W})$\n\nTherefore, to get the correct estimate of the total average causal effect, any of the aforementioned adjustment set will work; failing to do so will lead to bias.\n\n### Estimation\n\nFollowing the identification step is the estimation step. This step addresses a statistical question by determining how the causal effect identified in the previous step can be estimated. To perform this step, we used a parametric (model-based) estimator, specifically, linear regression. This was possible because we designed the illustrative examples to be simple and with a linear relationship between the variables. This way, we limited the complexity of the examples themselves and shifted the focus to the application of the backdoor criterion to define 'correct' adjustment sets.\n\nFor transparency and understanding, all (implicit) assumptions used for this illustrative example are (explicitly) provided in @tbl-summary.ex2.\n\n\n\n\n::: {#tbl-summary.ex2 .cell tbl-cap='Summary description of the simulation example'}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"pefclyqint\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#pefclyqint table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#pefclyqint thead, #pefclyqint tbody, #pefclyqint tfoot, #pefclyqint tr, #pefclyqint td, #pefclyqint th {\n  border-style: none;\n}\n\n#pefclyqint p {\n  margin: 0;\n  padding: 0;\n}\n\n#pefclyqint .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#pefclyqint .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#pefclyqint .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#pefclyqint .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#pefclyqint .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#pefclyqint .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pefclyqint .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#pefclyqint .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#pefclyqint .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#pefclyqint .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#pefclyqint .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#pefclyqint .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#pefclyqint .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#pefclyqint .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#pefclyqint .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#pefclyqint .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#pefclyqint .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#pefclyqint .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#pefclyqint .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pefclyqint .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#pefclyqint .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#pefclyqint .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#pefclyqint .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pefclyqint .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#pefclyqint .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#pefclyqint .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pefclyqint .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pefclyqint .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#pefclyqint .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pefclyqint .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#pefclyqint .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pefclyqint .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#pefclyqint .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pefclyqint .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#pefclyqint .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pefclyqint .gt_left {\n  text-align: left;\n}\n\n#pefclyqint .gt_center {\n  text-align: center;\n}\n\n#pefclyqint .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#pefclyqint .gt_font_normal {\n  font-weight: normal;\n}\n\n#pefclyqint .gt_font_bold {\n  font-weight: bold;\n}\n\n#pefclyqint .gt_font_italic {\n  font-style: italic;\n}\n\n#pefclyqint .gt_super {\n  font-size: 65%;\n}\n\n#pefclyqint .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#pefclyqint .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#pefclyqint .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#pefclyqint .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#pefclyqint .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#pefclyqint .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#pefclyqint .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#pefclyqint .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#pefclyqint div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {\n  height: 0px !important;\n}\n</style>\n<table class=\"gt_table\" style=\"table-layout:fixed;\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <colgroup>\n    <col style=\"width:22%;\"/>\n    <col/>\n  </colgroup>\n  \n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"colA\" class=\"gt_row gt_left\" style=\"vertical-align: top; font-weight: bold; background-color: #FFFFFF;\">Research question</td>\n<td headers=\"colB\" class=\"gt_row gt_left\" style=\"vertical-align: top;\">Total average causal effect (ACE) of social interaction (I) on glare perception (G).</td></tr>\n    <tr><td headers=\"colA\" class=\"gt_row gt_left\" style=\"vertical-align: top; font-weight: bold; background-color: #FFFFFF;\">Assumptions</td>\n<td headers=\"colB\" class=\"gt_row gt_left\" style=\"vertical-align: top;\">Random sample (simple random sampling): everyone in the population has an equal chance of being selected into the sample.</td></tr>\n    <tr><td headers=\"colA\" class=\"gt_row gt_left\" style=\"border-top-width: 0px; border-top-style: solid; border-top-color: #000000; border-bottom-width: 0px; border-bottom-style: solid; border-bottom-color: #000000; vertical-align: top; font-weight: bold; background-color: #FFFFFF;\"></td>\n<td headers=\"colB\" class=\"gt_row gt_left\" style=\"vertical-align: top;\">Limited random variability: large sample size.</td></tr>\n    <tr><td headers=\"colA\" class=\"gt_row gt_left\" style=\"border-top-width: 0px; border-top-style: solid; border-top-color: #000000; border-bottom-width: 0px; border-bottom-style: solid; border-bottom-color: #000000; vertical-align: top; font-weight: bold; background-color: #FFFFFF;\"></td>\n<td headers=\"colB\" class=\"gt_row gt_left\" style=\"vertical-align: top;\">Independence of observations: each observation represents independent bits of information.</td></tr>\n    <tr><td headers=\"colA\" class=\"gt_row gt_left\" style=\"border-top-width: 0px; border-top-style: solid; border-top-color: #000000; border-bottom-width: 0px; border-bottom-style: solid; border-bottom-color: #000000; vertical-align: top; font-weight: bold; background-color: #FFFFFF;\"></td>\n<td headers=\"colB\" class=\"gt_row gt_left\" style=\"vertical-align: top;\">No confounding: the DAG includes all shared causes among the variables.</td></tr>\n    <tr><td headers=\"colA\" class=\"gt_row gt_left\" style=\"border-top-width: 0px; border-top-style: solid; border-top-color: #000000; border-bottom-width: 0px; border-bottom-style: solid; border-bottom-color: #000000; vertical-align: top; font-weight: bold; background-color: #FFFFFF;\"></td>\n<td headers=\"colB\" class=\"gt_row gt_left\" style=\"vertical-align: top;\">No model error: perfect functional form specification.</td></tr>\n    <tr><td headers=\"colA\" class=\"gt_row gt_left\" style=\"border-top-width: 0px; border-top-style: solid; border-top-color: #000000; border-bottom-width: 0px; border-bottom-style: solid; border-bottom-color: #000000; vertical-align: top; font-weight: bold; background-color: #FFFFFF;\"></td>\n<td headers=\"colB\" class=\"gt_row gt_left\" style=\"vertical-align: top;\">No measurement error: all variables are measured perfectly.</td></tr>\n    <tr><td headers=\"colA\" class=\"gt_row gt_left\" style=\"vertical-align: top; font-weight: bold; background-color: #FFFFFF;\">Variables</td>\n<td headers=\"colB\" class=\"gt_row gt_left\" style=\"vertical-align: top;\">Social interaction (T): discrete (count) variable [unit: -]</td></tr>\n    <tr><td headers=\"colA\" class=\"gt_row gt_left\" style=\"border-top-width: 0px; border-top-style: solid; border-top-color: #000000; border-bottom-width: 0px; border-bottom-style: solid; border-bottom-color: #000000; vertical-align: top; font-weight: bold; background-color: #FFFFFF;\"></td>\n<td headers=\"colB\" class=\"gt_row gt_left\" style=\"vertical-align: top;\">Occupancy (O): categorical variable ['low'; 'high']</td></tr>\n    <tr><td headers=\"colA\" class=\"gt_row gt_left\" style=\"border-top-width: 0px; border-top-style: solid; border-top-color: #000000; border-bottom-width: 0px; border-bottom-style: solid; border-bottom-color: #000000; vertical-align: top; font-weight: bold; background-color: #FFFFFF;\"></td>\n<td headers=\"colB\" class=\"gt_row gt_left\" style=\"vertical-align: top;\">CO2 concentration (H): continous variable [unit: ppm]</td></tr>\n    <tr><td headers=\"colA\" class=\"gt_row gt_left\" style=\"border-top-width: 0px; border-top-style: solid; border-top-color: #000000; border-bottom-width: 0px; border-bottom-style: solid; border-bottom-color: #000000; vertical-align: top; font-weight: bold; background-color: #FFFFFF;\"></td>\n<td headers=\"colB\" class=\"gt_row gt_left\" style=\"vertical-align: top;\">Window state (W): categorical variable ['closed'; 'open']</td></tr>\n    <tr><td headers=\"colA\" class=\"gt_row gt_left\" style=\"border-top-width: 0px; border-top-style: solid; border-top-color: #000000; border-bottom-width: 0px; border-bottom-style: solid; border-bottom-color: #000000; vertical-align: top; font-weight: bold; background-color: #FFFFFF;\"></td>\n<td headers=\"colB\" class=\"gt_row gt_left\" style=\"vertical-align: top;\">Glare perception (G): continous variable [unit: -]</td></tr>\n  </tbody>\n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\n\n\nTo carry out the estimation step, we utilised linear regression within both the frequentist and Bayesian frameworks. Specifically, we will run three regression models:\n\n-   `Model.1` will include only social interaction $(\\text{I})$ as predictor;\n-   `Model.2` will include social interaction $(\\text{I})$ and CO~2~ concentration $(\\text{C})$ as predictors.\n-   `Model.3` will include social interaction $(\\text{I})$, CO~2~ concentration $(\\text{C})$ and window state $(\\text{W})$ as predictors.\n\nThe results of the fitted statistical models (i.e., `Model.1`, `Model.2` and `Model.3`) are presented here.\n\n#### Frequentist framework\n\n<details>\n\n<summary>Click to expand</summary>\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Fit the linear regression model with I and G (Model 1)\nex2_Model.1 <-\n  lm(formula = G ~ I,\n     data = ex2_sample.random)\n#View of the model summary\nsummary(ex2_Model.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = G ~ I, data = ex2_sample.random)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-27.8784  -9.9755  -0.2005  10.0889  25.5743 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 59.29801    0.43856   135.2   <2e-16 ***\nI           -1.92618    0.04756   -40.5   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.21 on 4998 degrees of freedom\nMultiple R-squared:  0.2471,\tAdjusted R-squared:  0.2469 \nF-statistic:  1640 on 1 and 4998 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Fit the linear regression model with I, C and G (Model 2)\nex2_Model.2 <-\n  lm(formula = G ~ I + C,\n     data = ex2_sample.random)\n#View of the model summary\nsummary(ex2_Model.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = G ~ I + C, data = ex2_sample.random)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-29.1718  -7.1808  -0.1675   7.4538  28.7898 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -17.57969    2.04883   -8.58   <2e-16 ***\nI            -2.62628    0.04568  -57.49   <2e-16 ***\nC             0.18872    0.00494   38.21   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.862 on 4997 degrees of freedom\nMultiple R-squared:  0.4173,\tAdjusted R-squared:  0.4171 \nF-statistic:  1789 on 2 and 4997 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Fit the linear regression model with I, C, W and G (Model 3)\nex2_Model.3 <-\n  lm(formula = G ~ I + C + W,\n     data = ex2_sample.random)\n#View of the model summary\nsummary(ex2_Model.3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = G ~ I + C + W, data = ex2_sample.random)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.1535  -3.4904   0.0251   3.4565  18.6750 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 50.759671   1.198330  42.359   <2e-16 ***\nI           -1.975151   0.024053 -82.115   <2e-16 ***\nC           -0.002258   0.003002  -0.752    0.452    \nWopen       20.079323   0.169566 118.416   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.055 on 4996 degrees of freedom\nMultiple R-squared:  0.8469,\tAdjusted R-squared:  0.8468 \nF-statistic:  9214 on 3 and 4996 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\nThe estimated coefficients for the three models are then plotted in @fig-DAG.ex2-estimate.\n\n\n\n\n::: {.cell .fig-cap-location-bottom layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nb_socint.glare = -2\n\ndata.frame(model = c('Model.1', 'Model.2', 'Model.3'),\n           estimate = c(coef(ex2_Model.1)['I'], \n                        coef(ex2_Model.2)['I'], \n                        coef(ex2_Model.3)['I']),\n           lower.95.CI = c(confint(ex2_Model.1, level = 0.95, type = 'Wald')['I', 1],\n                           confint(ex2_Model.2, level = 0.95, type = 'Wald')['I', 1],\n                           confint(ex2_Model.3, level = 0.95, type = 'Wald')['I', 1]),\n           upper.95.CI = c(confint(ex2_Model.1, level = 0.95, type = 'Wald')['I', 2],\n                           confint(ex2_Model.2, level = 0.95, type = 'Wald')['I', 2],\n                           confint(ex2_Model.3, level = 0.95, type = 'Wald')['I', 2])) %>%\n  \nggplot(aes(x = estimate, y = model, xmin = lower.95.CI, xmax = upper.95.CI)) + \n  geom_vline(xintercept = b_socint.glare, alpha = 0.8, linetype = 'dashed', colour = 'blue') + \n  geom_linerange() +\n  geom_point(shape = 21, size = 2, fill = 'white', stroke = 1) +\n  scale_x_continuous('Estimate', \n                     breaks = seq(from = -5, to = 5, by = 0.25),\n                     limits = c(-3, -1.5)) +\n  theme(panel.grid = element_blank(),\n        panel.background = element_blank(),\n        panel.border = element_rect(colour = 'black', fill = NA),\n        axis.title.y = element_blank())\n```\n\n::: {.cell-output-display}\n![Estimates of the social interaction coefficient for the three models. The white dots represent the point estimate, and the black lines represent the 95% confidence intervals. The blue dashed line represents the parameter used to generate the data.](ex2_simulation_files/figure-html/fig-DAG.ex2-estimate-1.png){#fig-DAG.ex2-estimate fig-align='center' width=5400}\n:::\n:::\n\n\n\n\n@fig-DAG.ex2-estimate shows the estimates (point estimate and 95 confidence interval) of the coefficient for social interaction for `Model.1`, `Model.2` and `Model.3`.\n\nFor `Model.1` we found a negative coefficient between social interaction $(\\text{I})$ and glare perception $(\\text{G})$ equal to -1.926 with 95% CI \\[-2.019, -1.833\\]. Since the 95% CI excludes zero, the regression coefficient is statistically significantly different from zero at the 0.05 level (p-value = 2.35e-310). Additionally, since the 95% CI includes the data-generating parameter for social interaction (i.e., `b_socint.glare = -2`), we can deduce that the estimated coefficient for social interaction is not statistically significantly different from -2 at the 0.05 level. We can test this more formally by using the `linearHypothesis()` function. Specifically,\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Test for I = -2\ncar::linearHypothesis(ex2_Model.1, 'I = -2') # car:: access the function from the car package without loading it in the environment \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nLinear hypothesis test:\nI = - 2\n\nModel 1: restricted model\nModel 2: G ~ I\n\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1   4999 628314                           \n2   4998 628012  1    302.67 2.4088 0.1207\n```\n\n\n:::\n:::\n\n\n\n\nThe resulting p-value is 0.121, which indicates that we fail to reject the null hypothesis (i.e., `I = -2`) at the 0.05 level. This result suggests that the regression coefficient for social interaction (i.e., -1.926) is not statistically significantly different from -2. Since the estimated causal effect from `Model.1` is unbiased, we would correctly conclude that an increase of unit in social interaction causes a decrease in glare perception by -1.926 units (95% CI \\[-2.019, -1.833\\]).\n\nFor `Model.2` we found a negative coefficient between coefficient between social interaction $(\\text{I})$ and glare perception $(\\text{G})$ equal to -2.626 with 95% CI \\[-2.716, -2.537\\]. Since the 95% CI excludes zero, the regression coefficient is statistically significantly different from zero at the 0.05 level (p-value = 0). Additionally, since the 95% CI does not include the data-generating parameter for social interaction (i.e., `b_socint.glare = -2`), we can deduce that the estimated coefficient for social interaction is statistically significantly different from -2 at the 0.05 level (although this will be the case for all numbers within the 95% confidence interval). We can test this more formally by using the `linearHypothesis()` function. Specifically,\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Test for I = -2\ncar::linearHypothesis(ex2_Model.2, 'I = -2') # car:: access the function from the car package without loading it in the environment \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nLinear hypothesis test:\nI = - 2\n\nModel 1: restricted model\nModel 2: G ~ I + C\n\n  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    \n1   4998 504312                                  \n2   4997 486032  1     18280 187.94 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\nThe resulting p-value is 5.11e-42, which indicates that we can reject the null hypothesis (i.e., `I = -2`) at the 0.05 level. This result suggests that the regression coefficient for social interaction (i.e., -2.626) is statistically significantly different from -2. Since the estimated causal effect from `Model.2` is biased, we would erroneously conclude that an increase of unit in social interaction causes a decrease in glare perception by -2.626 units (95% CI \\[-2.716, -2.537\\]).\n\nFor `Model.3` we found a negative coefficient between social interaction $(\\text{I})$ and glare perception $(\\text{G})$ equal to -1.975 with 95% CI \\[-2.022, -1.928\\]. Since the 95% CI excludes zero, the regression coefficient is statistically significantly different from zero at the 0.05 level (p-value = 0). Additionally, since the 95% CI includes the data-generating parameter for social interaction (i.e., `b_socint.glare = -2`), we can deduce that the estimated coefficient for social interaction is not statistically significantly different from -2 at the 0.05 level. We can test this more formally by using the `linearHypothesis()` function. Specifically,\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Test for I = -2\ncar::linearHypothesis(ex2_Model.3, 'I = -2') # car:: access the function from the car package without loading it in the environment \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nLinear hypothesis test:\nI = - 2\n\nModel 1: restricted model\nModel 2: G ~ I + C + W\n\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1   4997 127705                           \n2   4996 127678  1    27.275 1.0673 0.3016\n```\n\n\n:::\n:::\n\n\n\n\nThe resulting p-value is 0.302, which indicates that we fail to reject the null hypothesis (i.e., `I = -2`) at the 0.05 level. This result suggests that the regression coefficient for social interaction (i.e., -1.975) is not statistically significantly different from -2. Since the estimated causal effect from `Model.3` is unbiased, we would correctly conclude that an increase of unit in social interaction causes a decrease in glare perception by -1.975 units (95% CI \\[-2.022, -1.928\\]).\n\nImportantly, for `Model.1`, `Model.2`, and `Model.3`, the 95% confidence interval means that if we were to repeat the sampling process and calculate the interval many times, 95% of those calculated intervals would contain the true population parameter. To highlight this, we can repeat the analysis by fitting the three models to one thousand data sets randomly selected from our population.\n\nThe for-loop shown in the code below performs the following operations. First, sample (using simple random sample) a data set of 5,000 observations from the target population. Subsequently, perform linear regression using `Model.1`, `Model.2` and `Model.3` and store the estimated coefficients for `interaction`, its standard error and 95% confidence interval in the data frame `coefs_ex2`. This operation is repeated a thousand times, resulting in the data frame `coefs_ex2` containing the estimates (point estimate, standard error and confidence interval) of a thousand random samples of size 5,000 using `Model.1`, `Model.2` and `Model.3`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_model <- c('mod.1', 'mod.2', 'mod.3')     \n\nn_row <- n_sims*length(n_model)\n\n#Create an empty data frame\nempty.df <- data.frame(matrix(NA, nrow = n_row, ncol = 7))\n#Rename the data frame columns\ncolnames(empty.df) <- c('sim.id', 'estimate', 'se', 'CI_2.5', 'CI_97.5',\n                        'model', 'coverage')\n\n#Sample a thousand data sets of 5,000 observations and perform linear regression \ncoefs_ex2 <- empty.df #assign the empty data frame\nk = 1\nfor (i in 1:n_sims){\n  set.seed(ex2_random.seed[i]) #set unique seed for each simulation \n#Sample data set from population   \n  sample.random <- \n    ex2_population %>% \n    slice_sample(n = 5e3) #take a simple random sample of size 5,000\n#Fit models\n  for (j in 1:length(n_model)){\n    if (n_model[j] == 'mod.1'){\n      fit <- lm(formula = G ~ I,\n                data = sample.random)\n    } else if (n_model[j] == 'mod.2'){\n      fit <- lm(formula = G ~ I + C,\n                data = sample.random)  \n    } else {\n      fit <- lm(formula = G ~ I + C + W,\n                data = sample.random)\n    }  \n#Compile matrix  \n  coefs_ex2[k, 1] <- i #simulation ID\n  coefs_ex2[k, 2] <- coef(fit)['I'] #point estimate\n  coefs_ex2[k, 3] <- summary(fit)$coef['I','Std. Error'] #standard error\n  coefs_ex2[k, 4:5] <- confint(fit, level = 0.95, type = 'Wald')['I', ] #confidence interval (Wald)\n  coefs_ex2[k, 6] <- n_model[j] #sample size\n  k = k + 1\n  }\n}\ncoefs_ex2 <- as_tibble(coefs_ex2)\n#View the data frame\ncoefs_ex2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3,000 × 7\n   sim.id estimate     se CI_2.5 CI_97.5 model coverage\n    <int>    <dbl>  <dbl>  <dbl>   <dbl> <chr> <lgl>   \n 1      1    -1.93 0.0476  -2.02   -1.83 mod.1 NA      \n 2      1    -2.63 0.0457  -2.72   -2.54 mod.2 NA      \n 3      1    -1.98 0.0241  -2.02   -1.93 mod.3 NA      \n 4      2    -2.08 0.0483  -2.17   -1.98 mod.1 NA      \n 5      2    -2.71 0.0452  -2.80   -2.62 mod.2 NA      \n 6      2    -2.04 0.0242  -2.09   -1.99 mod.3 NA      \n 7      3    -2.07 0.0483  -2.16   -1.97 mod.1 NA      \n 8      3    -2.65 0.0457  -2.74   -2.56 mod.2 NA      \n 9      3    -1.99 0.0238  -2.03   -1.94 mod.3 NA      \n10      4    -2.01 0.0481  -2.10   -1.92 mod.1 NA      \n# ℹ 2,990 more rows\n```\n\n\n:::\n:::\n\n\n\n\nThe `coverage` is defined by setting its value to `1` if the confidence interval overlaps the data-generating parameter for `interaction` (i.e., `b_socint.glare = -2`) and `0` otherwise.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Calculate coverage\ncoefs_ex2 <-\n  coefs_ex2 %>%\n  mutate(coverage = case_when(CI_2.5 > b_socint.glare | CI_97.5 < b_socint.glare ~ 0,\n                              CI_2.5 <= b_socint.glare & CI_97.5 >= b_socint.glare ~ 1,\n                              .default = NA))\n#View the data frame\ncoefs_ex2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3,000 × 7\n   sim.id estimate     se CI_2.5 CI_97.5 model coverage\n    <int>    <dbl>  <dbl>  <dbl>   <dbl> <chr>    <dbl>\n 1      1    -1.93 0.0476  -2.02   -1.83 mod.1        1\n 2      1    -2.63 0.0457  -2.72   -2.54 mod.2        0\n 3      1    -1.98 0.0241  -2.02   -1.93 mod.3        1\n 4      2    -2.08 0.0483  -2.17   -1.98 mod.1        1\n 5      2    -2.71 0.0452  -2.80   -2.62 mod.2        0\n 6      2    -2.04 0.0242  -2.09   -1.99 mod.3        1\n 7      3    -2.07 0.0483  -2.16   -1.97 mod.1        1\n 8      3    -2.65 0.0457  -2.74   -2.56 mod.2        0\n 9      3    -1.99 0.0238  -2.03   -1.94 mod.3        1\n10      4    -2.01 0.0481  -2.10   -1.92 mod.1        1\n# ℹ 2,990 more rows\n```\n\n\n:::\n:::\n\n\n\n\nThe results are then plotted in @fig-DAG.ex2-CI.\n\n\n\n\n::: {.cell .fig-cap-location-bottom layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nmodel_names <- c('mod.1' = 'Model.1', \n                 'mod.2' = 'Model.2',\n                 'mod.3' = 'Model.3')\n\nggplot(data = subset(coefs_ex2, sim.id <= 2e2), aes(x = sim.id, y = estimate, ymin = CI_2.5, ymax = CI_97.5, colour = as.factor(coverage))) + \n  geom_hline(yintercept = b_socint.glare, alpha = 0.8, linetype = 'dashed', colour = 'blue') + \n  geom_linerange() +\n  geom_point(shape = 21, size = 1, fill = 'white', stroke = 0.5) +\n  scale_colour_manual('', values = c('black', '#FF4040'),\n                      breaks = c('1','0')) +\n  scale_y_continuous('Estimate') +\n  scale_x_continuous('Simulation ID') +\n  facet_wrap(model~., \n             labeller = labeller(model = model_names),\n             nrow = 3,\n             scales = 'fixed') +\n  theme(legend.position = 'none', \n        panel.grid = element_blank(),\n        panel.background = element_blank(),\n        panel.border = element_rect(colour = 'black', fill = NA),\n        axis.title.y = element_blank())\n```\n\n::: {.cell-output-display}\n![Estimates of the social interaction coefficient (only the first hundreds of the thousand simulations are shown). The white dots represent the point estimate, and the black lines represent the 95% confidence intervals. In red are highlighted the confidence intervals that do not overlap the parameter used to generate the data (dashed blue line).](ex2_simulation_files/figure-html/fig-DAG.ex2-CI-1.png){#fig-DAG.ex2-CI fig-align='center' width=5400}\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n@fig-DAG.ex2-CI shows the first 200 estimates (point estimate and confidence interval) of the coefficient for social interaction for `Model.1`, `Model.2` and `Model.3`. If all the thousand simulations are considered, the frequency of the coverage of the calculated confidence intervals (i.e., how many times the confidence intervals overlap the data-generating parameter) is 94.6%, 0.0% and 94.4% for `Model.1`, `Model.2` and `Model.3`, respectively. Since the estimate of the causal effect for `Model.2` are biased, the calculated confidence intervals for this model do not have the expected coverage. In fact, confidence intervals only quantify the uncertainty due to random error (i.e., sample variability), not systematic error (i.e., bias). Instead, the estimate from `Model.1` and `Model.3` are unbiased and the calculated 95% confidence intervals have the expected coverage (i.e., overlap the data-generating parameter 95% of the times).\n\nWe can also visualize all the 1,000 the estimates of the coefficient for social interaction for `Model.1`, `Model.2` and `Model.3` (i.e., the white dots in @fig-DAG.ex2-CI).\n\n\n\n\n::: {.cell .fig-cap-location-bottom layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(data = coefs_ex2, aes(x = estimate, y = ifelse(after_stat(count) > 0, after_stat(count), NA))) +\n  geom_histogram(binwidth = 0.02, fill = 'white', colour = 'grey50') +\n  geom_vline(xintercept = b_socint.glare, colour = 'blue', linetype = 'dashed') +\n  scale_x_continuous('Estimate', \n                     breaks = seq(from = -5, to = 5, by = 0.25),\n                     limits = c(-3, -1.5)) +\n  facet_grid(model~., \n             labeller = labeller(model = model_names),\n             scales = 'fixed') +\n  theme(axis.title.y = element_blank(), \n        axis.text.y = element_blank(), \n        axis.ticks.y = element_blank(),\n        panel.grid = element_blank(),\n        panel.background = element_blank(),\n        panel.border = element_rect(colour = 'black', fill = NA))\n```\n\n::: {.cell-output-display}\n![Histogram of the 1,000 estimates of the social interaction coefficient for the three models. The blue dashed line represents the parameter used to generate the data.](ex2_simulation_files/figure-html/fig-DAG.ex2-mean-estimate-1.png){#fig-DAG.ex2-mean-estimate fig-align='center' width=5400}\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\nIn @fig-DAG.ex2-mean-estimate, the estimated coefficients are visualized through a histogram. Here, we can see that the estimates for `Model.2` are not clustered around the data-generating parameter (blue dashed line) having a mean estimate of -2.634 (with 0.044 standard deviation). In contrast, the estimates for `Model.1` and `Model.3` having a mean estimate of -1.994 (with 0.048 standard deviation) and -2.001 (with 0.025 standard deviation), respectively, are centered around the data-generating parameter.\n\nAs expected, since there is no backdoor path open, regressing glare perception $(\\text{G})$ on social interaction $(\\text{I})$ (i.e., using `Model.1`) leads to the correct estimate of the total average causal effect. However, when CO~2~ is included as a predictor (i.e., using `Model.2`) the estimates are biased. Adjusting for CO~2~ alone opens the backdoor path $\\text{I} \\leftarrow \\text{O} \\rightarrow \\text{C} \\leftarrow \\text{W} \\rightarrow \\text{G}$ that was previously closed. As a result, association can flow from $\\text{I}$ to $\\text{G}$ through $\\text{O}$, $\\text{C}$ and $\\text{W}$. This happens because CO~2~ is a collider. However, when we also include window state $(\\text{W})$ as a predictor (i.e., using `Model.3`) the backdoor path is closed, leading to the correct estimate of the total average causal effect of social interaction $(\\text{I})$ on glare perception $(\\text{G})$.\n\nThis bias is known as M-bias. Generally, adjusting for an inappropriate variable (a collider on a non-causal path) opens an M-shaped backdoor path and creates spurious association.\n\n</details>\n\n#### Bayesian framework\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Fit the linear regression model with I and G (Model 1)\nex2_Model.1 <- stan_glm(formula = G ~ I,\n                        family = gaussian(),\n                        data = ex2_sample.random,\n                        #Prior coefficients\n                        prior = normal(location = 0, scale = 4),\n                        #Prior intercept\n                        prior_intercept = normal(location = 50, scale = 10),\n                        #Prior sigma\n                        prior_aux = exponential(rate = 0.5),\n                        iter = 4000, warmup = 1000, \n                        save_warmup = TRUE,\n                        chains = 4, cores = 4,\n                        seed = 2025) #for reproducibility   \n#View of the model\nex2_Model.1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nstan_glm\n family:       gaussian [identity]\n formula:      G ~ I\n observations: 5000\n predictors:   2\n------\n            Median MAD_SD\n(Intercept) 59.3    0.4  \nI           -1.9    0.0  \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 11.2    0.1  \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Fit the linear regression model with I, C and G (Model 2)\nex2_Model.2 <- stan_glm(formula = G ~ I + C,\n                        family = gaussian(),\n                        data = ex2_sample.random,\n                        #Prior coefficients\n                        prior = normal(location = c(0, 0), scale = c(4, 1)),\n                        #Prior intercept\n                        prior_intercept = normal(location = 50, scale = 10),\n                        #Prior sigma\n                        prior_aux = exponential(rate = 0.5),\n                        iter = 4000, warmup = 1000, \n                        save_warmup = TRUE,\n                        chains = 4, cores = 4,\n                        seed = 2025) #for reproducibility\n#View of the model\nex2_Model.2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nstan_glm\n family:       gaussian [identity]\n formula:      G ~ I + C\n observations: 5000\n predictors:   3\n------\n            Median MAD_SD\n(Intercept) -17.5    2.0 \nI            -2.6    0.0 \nC             0.2    0.0 \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 9.9    0.1   \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Fit the linear regression model with I, C, W and G (Model 3)\nex2_Model.3 <- stan_glm(formula = G ~ I + C + W,\n                        family = gaussian(),\n                        data = ex2_sample.random,\n                        #Prior coefficients\n                        prior = normal(location = c(0, 0, 0), scale = c(4, 1, 40)),\n                        #Prior intercept\n                        prior_intercept = normal(location = 50, scale = 10),\n                        #Prior sigma\n                        prior_aux = exponential(rate = 0.5),\n                        iter = 4000, warmup = 1000, \n                        save_warmup = TRUE,\n                        chains = 4, cores = 4,\n                        seed = 2025) #for reproducibility\n#View of the model\nex2_Model.3\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nstan_glm\n family:       gaussian [identity]\n formula:      G ~ I + C + W\n observations: 5000\n predictors:   4\n------\n            Median MAD_SD\n(Intercept) 50.8    1.2  \nI           -2.0    0.0  \nC            0.0    0.0  \nWopen       20.1    0.2  \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 5.1    0.1   \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n```\n\n\n:::\n:::\n\n\n\n\nIn Bayesian analysis, there are important diagnostics that have to be carried out in order to assessed the convergence and efficiency of the Markov Chains. This is done by using the `monitor()` function which computes summaries of MCMC (Markov Chain Monte Carlo) draws and monitor convergence. Specifically, we will look at `Rhat`, `Bulk_ESS` and `Tail_ESS` metrics.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Diagnostics for model 1\nmonitor(ex2_Model.1$stanfit)  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nInference for the input samples (4 chains: each with iter = 4000; warmup = 0):\n\n                    Q5      Q50      Q95     Mean  SD  Rhat Bulk_ESS Tail_ESS\n(Intercept)       58.6     59.3     60.0     59.3 0.4     1    11109     7597\nI                 -2.0     -1.9     -1.8     -1.9 0.0     1    11198     7423\nsigma             11.0     11.2     11.4     11.2 0.1     1    12198     8926\nmean_PPD          42.4     42.7     43.1     42.7 0.2     1    11230    10778\nlog-posterior -19189.8 -19187.1 -19186.1 -19187.4 1.2     1     5159     7821\n\nFor each parameter, Bulk_ESS and Tail_ESS are crude measures of \neffective sample size for bulk and tail quantities respectively (an ESS > 100 \nper chain is considered good), and Rhat is the potential scale reduction \nfactor on rank normalized split chains (at convergence, Rhat <= 1.05).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Diagnostics for model 2\nmonitor(ex2_Model.2$stanfit) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nInference for the input samples (4 chains: each with iter = 4000; warmup = 0):\n\n                    Q5      Q50      Q95     Mean  SD  Rhat Bulk_ESS Tail_ESS\n(Intercept)      -20.9    -17.5    -14.3    -17.6 2.0     1    14345     9537\nI                 -2.7     -2.6     -2.6     -2.6 0.0     1    11779     8439\nC                  0.2      0.2      0.2      0.2 0.0     1    13380     9184\nsigma              9.7      9.9     10.0      9.9 0.1     1    12884     9520\nmean_PPD          42.4     42.7     43.1     42.7 0.2     1    11998    10505\nlog-posterior -18550.3 -18547.3 -18546.0 -18547.6 1.4     1     5374     6558\n\nFor each parameter, Bulk_ESS and Tail_ESS are crude measures of \neffective sample size for bulk and tail quantities respectively (an ESS > 100 \nper chain is considered good), and Rhat is the potential scale reduction \nfactor on rank normalized split chains (at convergence, Rhat <= 1.05).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Diagnostics for model 3\nmonitor(ex2_Model.3$stanfit) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nInference for the input samples (4 chains: each with iter = 4000; warmup = 0):\n\n                    Q5      Q50      Q95     Mean  SD  Rhat Bulk_ESS Tail_ESS\n(Intercept)       48.8     50.8     52.8     50.8 1.2     1    10783     9224\nI                 -2.0     -2.0     -1.9     -2.0 0.0     1     9359     8154\nC                  0.0      0.0      0.0      0.0 0.0     1     9643     8274\nWopen             19.8     20.1     20.4     20.1 0.2     1     9978     8954\nsigma              5.0      5.1      5.1      5.1 0.1     1     9898     8482\nmean_PPD          42.6     42.7     42.9     42.7 0.1     1     9558     9741\nlog-posterior -15208.6 -15205.1 -15203.5 -15205.5 1.6     1     5197     7655\n\nFor each parameter, Bulk_ESS and Tail_ESS are crude measures of \neffective sample size for bulk and tail quantities respectively (an ESS > 100 \nper chain is considered good), and Rhat is the potential scale reduction \nfactor on rank normalized split chains (at convergence, Rhat <= 1.05).\n```\n\n\n:::\n:::\n\n\n\n\n`Rhat` is a metric used to assess the convergence of Markov Chain Monte Carlo (MCMC) simulations. It helps determine if the MCMC chains have adequately explored the target posterior distribution. Specifically, it compares the between- and within-chain estimates for model parameters: If chains have not mixed well (i.e., the between- and within-chain estimates do not agree), R-hat is larger than 1. A general rule of thumb is to use the sample only if R-hat is less than 1.05; a larger value suggests that the chains have not mixed well, and the results might not be reliable. In our three models, all `Rhat` are equal to 1 indicating that the chains have mixed well and have adequately explored the target posterior distribution.\n\n`Bulk_ESS` and `Tail_ESS` stand for 'Bulk Effective Sample Size' and 'Tail Effective Sample Size,' respectively. Since MCMC samples are not truly independent (they are correlated), these metrics assess the sampling efficiencies, that is, they help evaluate how efficiently the MCMC sampler is exploring the parameters space.\n\n-   `Bulk_ESS` is useful measure for sampling efficiency in the bulk (center) of the distribution (e.g., efficiency of mean and median estimates);\n-   `Tail_ESS` is useful measure for sampling efficiency in the tails of the distribution (e.g., efficiency of variance and tail quantile estimates). A general rule of thumb is that both `Bulk-ESS` and `Tail-ESS` should be at least 100 (approximately) per Markov Chain in order to be reliable and indicate that estimates of respective posterior quantiles are reliable. In our three models, all `Bulk-ESS` and `Tail-ESS` are well above 400 (i.e., 100 multiplied by 4, the number of chains we used) indicating that estimates of posterior quantiles are reliable.\n\nSince we have established that the posteriors are reliable, we can now explore the model estimates.\n\nThe estimated coefficients for the three models are then plotted in @fig-DAG.ex2-estimate-Bayesian.\n\n\n\n\n::: {.cell .fig-cap-location-bottom layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\n#Extract draws from model 1 \npost_ex2_Model.1 <-\n  ex2_Model.1 %>% \n  spread_draws(I) %>% #extract draws from the fitted model\n  mutate(model = 'Model.1') #add a new column to specify that the model\n\n#Extract draws from model 2\npost_ex2_Model.2 <-\n  ex2_Model.2 %>% \n  spread_draws(I) %>% #extract draws from the fitted model\n  mutate(model = 'Model.2') #add a new column to specify that the model\n\n#Extract draws from model 3\npost_ex2_Model.3 <-\n  ex2_Model.3 %>% \n  spread_draws(I) %>% #extract draws from the fitted model\n  mutate(model = 'Model.3') #add a new column to specify that the model\n\n#Combine draws\nplot.post <- rbind(post_ex2_Model.1, post_ex2_Model.2, post_ex2_Model.3)\n\n# Plot\nplot.post  %>%\n  ggplot(aes(y = model, x = I)) +\n  geom_vline(xintercept = b_socint.glare, alpha = 0.8, linetype = 'dashed', colour = 'blue') + \n  stat_slabinterval(point_interval = 'mean_hdi',\n                    .width = c(.95)) +\n  scale_x_continuous('Estimate', \n                     breaks = seq(from = -5, to = 5, by = 0.25),\n                     limits = c(-3, -1.5)) +\n  theme(panel.grid = element_blank(),\n        panel.background = element_blank(),\n        panel.border = element_rect(colour = 'black', fill = NA),\n        axis.title.y = element_blank())\n```\n\n::: {.cell-output-display}\n![Posterior distribution of the social interaction coefficient for the three models. The black line and dot at the bottom of each distribution represent the highest density interval (HDI) and the mean, respectively.](ex2_simulation_files/figure-html/fig-DAG.ex2-estimate-Bayesian-1.png){#fig-DAG.ex2-estimate-Bayesian fig-align='center' width=5400}\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n@fig-DAG.ex2-estimate-Bayesian shows the estimates (mean and 95 HDI) of the coefficient for social interaction for `Model.1`, `Model.2` and `Model.3`.\n\nFor `Model.1` we found a negative coefficient between social interaction $(\\text{I})$ and glare perception $(\\text{G})$ (mean = -1.927, 95% HDI \\[-2.022, -1.835\\]). The estimated causal effect is unbiased, leading to the correct conclusion that an increase of unit in social interaction causes a decrease in glare perception by -1.927 units, on average.\n\nFor `Model.2` we found a negative coefficient between social interaction $(\\text{I})$ and glare perception $(\\text{G})$ (mean = -2.625, 95% HDI \\[-2.714, -2.537\\]). However, the estimated causal effect is biased, leading to the wrong conclusion that an increase of unit in social interaction causes a decrease in glare perception by -2.625 units, on average.\n\nFor `Model.3` we found a negative coefficient between social interaction $(\\text{I})$ and glare perception $(\\text{G})$ (mean = -1.975, 95% HDI \\[-2.023, -1.928\\]). However, now the estimated causal effect is unbiased, leading to the correct conclusion that an increase of unit in social interaction causes a decrease in glare perception by -1.975 units, on average.\n\nImportantly, for both `Model.1`, `Model.2` and `Model.3`, the 95% HDI is the range of parameter values within which the most credible 95% of the posterior distribution falls. Unlike frequentist confidence interval, the Bayesian 95% HDI has a direct probabilistic meaning: every point inside the HDI has a higher probability density than any point outside the interval. Therefore, given the model, the prior and the data, we can say that there is a 95% probability that the data-generating parameter (i.e., `b_socint.glare = -2`) lies within the HDI. However, since `Model.2` leads to a biased estimate, we will reach the wrong conclusion by stating that there is a 95% probability that the data-generating parameter lies within the \\[-2.714, -2.537\\] interval. This probability is 0%.\n\nAs expected, since there is no backdoor path open, regressing glare perception $(\\text{G})$ on social interaction $(\\text{I})$ (i.e., using `Model.1`) leads to the correct estimate of the total average causal effect. However, when CO~2~ is included as a predictor (i.e., using `Model.2`) the estimates are biased. Adjusting for CO~2~ alone opens the backdoor path $\\text{I} \\leftarrow \\text{O} \\rightarrow \\text{C} \\leftarrow \\text{W} \\rightarrow \\text{G}$ that was previously closed. As a result, association can flow from $\\text{I}$ to $\\text{G}$ through $\\text{O}$, $\\text{C}$ and $\\text{W}$. This happens because CO~2~ is a collider. However, when we also include window state $(\\text{W})$ as a predictor (i.e., using `Model.3`) the backdoor path is closed, leading to the correct estimate of the total total average causal effect of social interaction $(\\text{I})$ on glare perception $(\\text{G})$.\n\nThis bias is known as M-bias. Generally, adjusting for an inappropriate variable (a collier on a non-causal path) opens an M-shaped backdoor path and creates spurious association.\n\n## Session info {.unnumbered}\n\nVersion information about R, the OS and attached or loaded packages.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.2.3 (2023-03-15 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 26200)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=English_United Kingdom.utf8 \n[2] LC_CTYPE=English_United Kingdom.utf8   \n[3] LC_MONETARY=English_United Kingdom.utf8\n[4] LC_NUMERIC=C                           \n[5] LC_TIME=English_United Kingdom.utf8    \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] rstan_2.32.7        StanHeaders_2.32.10 gt_1.1.0           \n [4] lubridate_1.9.4     forcats_1.0.1       stringr_1.6.0      \n [7] dplyr_1.1.4         purrr_1.2.0         readr_2.1.6        \n[10] tidyr_1.3.1         tibble_3.3.0        ggplot2_4.0.1      \n[13] tidyverse_2.0.0     ggdist_3.3.3        tidybayes_3.0.7    \n[16] rstanarm_2.32.2     Rcpp_1.1.0          dagitty_0.3-4      \n[19] ggdag_0.2.13       \n\nloaded via a namespace (and not attached):\n  [1] backports_1.5.0       plyr_1.8.9            igraph_2.2.1         \n  [4] splines_4.2.3         svUnit_1.0.8          crosstalk_1.2.2      \n  [7] rstantools_2.5.0      inline_0.3.21         digest_0.6.38        \n [10] htmltools_0.5.8.1     viridis_0.6.5         magrittr_2.0.4       \n [13] checkmate_2.3.3       memoise_2.0.1         tzdb_0.5.0           \n [16] graphlayouts_1.2.2    RcppParallel_5.1.11-1 matrixStats_1.5.0    \n [19] xts_0.14.1            timechange_0.3.0      colorspace_2.1-2     \n [22] ggrepel_0.9.6         rbibutils_2.4         xfun_0.54            \n [25] jsonlite_2.0.0        lme4_1.1-37           survival_3.8-3       \n [28] zoo_1.8-14            glue_1.8.0            reformulas_0.4.2     \n [31] polyclip_1.10-7       gtable_0.3.6          V8_8.0.1             \n [34] distributional_0.5.0  car_3.1-3             pkgbuild_1.4.8       \n [37] abind_1.4-8           scales_1.4.0          miniUI_0.1.2         \n [40] viridisLite_0.4.2     xtable_1.8-4          Formula_1.2-5        \n [43] stats4_4.2.3          DT_0.34.0             htmlwidgets_1.6.4    \n [46] threejs_0.3.4         arrayhelpers_1.1-0    RColorBrewer_1.1-3   \n [49] posterior_1.6.1       pkgconfig_2.0.3       loo_2.8.0            \n [52] farver_2.1.2          sass_0.4.10           utf8_1.2.6           \n [55] tidyselect_1.2.1      labeling_0.4.3        rlang_1.1.6          \n [58] reshape2_1.4.5        later_1.4.4           tools_4.2.3          \n [61] cachem_1.1.0          cli_3.6.5             generics_0.1.4       \n [64] evaluate_1.0.5        fastmap_1.2.0         yaml_2.3.10          \n [67] knitr_1.50            fs_1.6.6              tidygraph_1.3.1      \n [70] ggraph_2.2.2          nlme_3.1-168          mime_0.13            \n [73] xml2_1.5.0            compiler_4.2.3        bayesplot_1.14.0     \n [76] shinythemes_1.2.0     rstudioapi_0.17.1     curl_7.0.0           \n [79] tweenr_2.0.3          stringi_1.8.7         lattice_0.22-7       \n [82] Matrix_1.6-5          nloptr_2.2.1          markdown_2.0         \n [85] shinyjs_2.1.0         tensorA_0.36.2.1      vctrs_0.6.5          \n [88] pillar_1.11.1         lifecycle_1.0.4       Rdpack_2.6.4         \n [91] httpuv_1.6.16         QuickJSR_1.8.1        R6_2.6.1             \n [94] promises_1.5.0        gridExtra_2.3         codetools_0.2-20     \n [97] boot_1.3-32           colourpicker_1.3.0    MASS_7.3-58.2        \n[100] gtools_3.9.5          withr_3.0.2           shinystan_2.6.0      \n[103] parallel_4.2.3        hms_1.1.4             grid_4.2.3           \n[106] coda_0.19-4.1         minqa_1.2.8           rmarkdown_2.30       \n[109] S7_0.2.1              carData_3.0-5         otel_0.2.0           \n[112] ggforce_0.5.0         shiny_1.11.1          base64enc_0.1-3      \n[115] dygraphs_1.1.1.6     \n```\n\n\n:::\n:::\n",
    "supporting": [
      "ex2_simulation_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}